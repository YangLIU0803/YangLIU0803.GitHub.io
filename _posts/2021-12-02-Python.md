---
layout: article
title: 在学校做过的Python
key: 10003
tags: Python
category: blog
date: 2021-12-02 14:50:00 +08:00
modify_date: 2021-12-03 11:40:00 +08:00
picture_frame: shadow
---
想要整理一下曾经在学校中做过的python数据处理及可视化项目。
以及想念zjc老师。

**还在更新中。**
<!--more-->

### 词云

– 针对一个文本文档，读入并分词，过滤停用词，
统计所有词的频率，排序输出前topn个词。
– 对所有出现的词依一定规则进行过滤，得到特
征词，将文档用特征词表示为向量。
– 可视化为关键词云。
– 待分析的文本文件：doc1.txt
– 停用词表： stopwords_list.txt
– 代码：w2demo1.py
根据提供的评论数据(online_reviews_texts.txt，见资源/data，一行一条评论，因此一行可以视为一个文档，行号可以作为文档编号），读入所有文档并分词，统计词频，找到高频词，确实特征集，为每一条评论生成向量表示，计算一下不同评论之间的距离（自定义，如欧氏或余弦），能不能找到所有评论的“重心”或者所有评论中的代表性评论并输出原文？除了词云外，针对多文档数据还有别的可视化方式没有？
